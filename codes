
#################################################################
#==============R Codes for Multivariate Analysis================#
#============Email: alireza.ahmadi@modares.ac.ir================#
#################################################################
#=================================
Preparation of data matrix
#=================================
#########First copy the data from the Excel file and then run the following commands
my_data <- read.table(file = "clipboard", 
                      sep = "\t", header=TRUE)
bodyfat <- as.matrix(my_data)
bodyfat<-data.matrix(bodyfat[,-c(1:3)])
#################################################################
#==========================PCA section==========================#
#################################################################
#=================================
#Covariance and correlation matrices
#=================================
print(bodyfat_cov<-round(cov(bodyfat),3))
print(bodyfat_corr<-round(cor(bodyfat),3))
#=================================
#Bartlett's sphericity test
#=================================
library("psych")
cortest.bartlett(bodyfat_corr,n=252)
#=================================
#Principal components analysis
#=================================
pca <- princomp(covmat = bodyfat_cov)
summary(pca, loadings = TRUE)
###############################
pca <- princomp(covmat = bodyfat_corr)
summary(pca, loadings = TRUE)
#=================================
#Estimating the number of PCs
#=================================
eigen(bodyfat_corr)$values
#################################################################
#==========================EFA section==========================#
#################################################################
#=================================
#Estimating the number of factors
#=================================
sapply(1:6, function(f)
factanal(covmat = bodyfat_cov, factors = f,
method = "mle", n.obs = 252)$PVAL)
plot(eigen(bodyfat_corr)$values,type="l",
ylab="eigenvalues",
xlab="number of factors", main="scree diagram")
#=================================
#Factor analysis
#=================================
factanal(covmat = bodyfat_cov, factors = 8,
method = "mle", n.obs = 252,lower = 1e-09)
#################################################################
#================Multidimensional scaling section===============#
#################################################################
#=================================
#classical multidimensional scaling
#=================================
my_data <- read_excel(file.choose())
bodyfat<-data.matrix(my_data[,-c(1:3)])
head(bodyfat)
dis<-dist(bodyfat, method="euclidean")
fit<-cmdscale(dis,k = 2, eig = TRUE)
#=================================
#checking adequacy of fitting
#=================================
fit_eigen <- fit$eig
P_criterion<-cumsum(abs(fit_eigen[1])) / sum(abs(fit_eigen))+
  cumsum(abs(fit_eigen[2])) / sum(abs(fit_eigen))
P_criterion
mean(abs(dist(bodyfat)))
mean(dist(cmdscale(dis,k = 2)))
mean(abs(dist(bodyfat) - dist(cmdscale(dis,k = 2))))
#=================================
#plotting the two-dimensional
#scaling solution
#=================================
plot(fit$points,xlab="Coordinate 1",ylab="Coordinate 2",col = "dark red")
text(fit$points, lables=bodyfat[,1],pos=3,cex=1,col = "dark blue")
#################################################################
#===========================ICA section=========================#
#################################################################
#=================================
#Preprocess the data by applying PCA
#to the sample correlation matrix.
#=================================
pca <- princomp(bodyfat, cor = TRUE)
summary(pca, loadings = TRUE)
#=================================
#Recycling sources
#=================================
require(fastICA)
npc<-sum(as.numeric(pca$sdev>1))
pc.scores<-pca$scores[,1:npc]
PCA.scores.unit<-apply(pc.scores,2,scale)
###############################
ICA<- fastICA(pc.scores, 2, alg.typ = "deflation", fun = "logcosh",
method = "R", row.norm = FALSE, maxit = 200, 
tol = 0.0001, verbose = TRUE)
par(mfcol = c(2, 2))
plot(1:252, pc.scores[,1 ], type = "l", main = "Pre-processed data", 
xlab = "", ylab = "",col="red")
plot(1:252, pc.scores[,2 ], type = "l", xlab = "", ylab = "",col="red")
plot(1:252, ICA$S[,1 ], type = "l", main = "ICA source estimates", 
xlab = "", ylab = "",col="blue")
plot(1:252, ICA$S[, 2], type = "l", xlab = "", ylab = "",col="blue")      
#################################################################
#====================Cluster analysis section===================#
#################################################################
#=================================
#Preparation of data matrix
#=================================
my_data <- read.table(file = "clipboard", 
sep = ,, header=TRUE)
bodyfat <- as.data.frame(my_data)
###############################
bodyfat<-data.matrix(bodyfat[,-c(1:3)])
bodyfat<-scale(bodyfat)
#=================================
#Scatter plot
#=================================
PCA.meg=princomp(bodyfat, cor = T)
PCA.scores<-PCA.meg$scores[,1:2]
plot(PCA.scores[,1],PCA.scores[,2])
text(PCA.scores[,1],PCA.scores[,2],labels=1:252)
#=================================
#Deleting outlier data
#=================================
bodyfat<-as.matrix(bodyfat)
bodyfat<-bodyfat[-c(31,39,41),]
#=================================
#Agglomerative hierarchical clustering
#=================================
par(mfrow = c(3, 1))
plot(hclust(dist(bodyfat),method="complete"),main="complete linkage")
rect.hclust(hclust(dist(bodyfat),method="complete"),k=2, border = "green")
rect.hclust(hclust(dist(bodyfat),method="complete"),k=3, border = "red")
rect.hclust(hclust(dist(bodyfat),method="complete"),k=4, border = "blue")
###############################
plot(hclust(dist(bodyfat),method="average"), main="average linkage")
rect.hclust(hclust(dist(bodyfat),method="average"),k=2, border = "green")
rect.hclust(hclust(dist(bodyfat),method="average"),k=3, border = "red")
rect.hclust(hclust(dist(bodyfat),method="average"),k=4, border = "blue")
###############################
plot(hclust(dist(bodyfat),method="single"),main="single linkage")
rect.hclust(hclust(dist(bodyfat),method="single"),k=2, border = "green")
rect.hclust(hclust(dist(bodyfat),method="single"),k=3, border = "red")
rect.hclust(hclust(dist(bodyfat),method="single"),k=4, border = "blue")
###############################
complete<-cutree(hclust(dist(bodyfat),method="complete"),3)
table(complete)
average<-cutree(hclust(dist(bodyfat),method="average"),3)
table(average)
single<-cutree(hclust(dist(bodyfat),method="single"),3)
table(single)
###############################
library(dendextend)
dend<-as.dendrogram(hclust(dist(bodyfat),method="complete"))
dend<-color_branches(dend,k=3,c("red","blue","green"))
plot(dend)
circlize_dendrogram(dend)
#=================================
#K-means clustering
#=================================
library(adegenet)
foo.WSS <- find.clusters(bodyfat, n.pca=2, choose=FALSE, stat="WSS")
plot(foo.WSS$Kstat, type="o", xlab="Number of clusters", ylab="Whithin groups sum of square", col="red", main="Detection based on WSS")
points(2, foo.WSS$Kstat[3], pch="x", cex=5)
###############################
results<-kmeans(bodyfat,3)
results
plot(bodyfat[,1],bodyfat[,2],col=results$cluster)
#=================================
#Model-based clustering
#=================================
library(mclust)
library(factoextra)
dens<-densityMclust(bodyfat)
plot(dens, what="density")
###############################
mc<-Mclust(bodyfat)
summary(mc)
plot(mc, what="BIC")
fviz_mclust_bic(mc)
fviz_cluster(mc, data=bodyfat,palette=c("red","blue"),geom = "point",ellipse.type =  "convex")
#=================================
#PAM clustering
#=================================
library(cluster)
fviz_nbclust(bodyfat,pam,method = "silhouette")
###############################
mypam<-pam(bodyfat,2,metric = "euclidean",stand=F)
fviz_cluster(mypam, data=bodyfat,palette=c("red","blue"),geom = "point",ellipse.type =  "convex")
###############################
sil<-silhouette(mypam$cluster,dist = dist(bodyfat))
fviz_silhouette(sil)
#=================================
#SOM map
#=================================
library(kohonen)
g<-somgrid(xdim=4,ydim=4,topo="rectangular")
map<-som(bodyfat,grid=g,alpha=c(0.05,0.01),radius=1)
plot(map)
plot(map,type="mapping",labels=1:252)
plot(map,type="dist.neighbours")
#################################################################
#================ Discrimination Analysis section===============#
#################################################################
#=================================
#creating classes based on PCA
#=================================
library("readxl")
my_data <- read_excel(file.choose())
bodyfat<-data.matrix(my_data[,-c(1:3)])
pca <- princomp(bodyfat, cor = TRUE)
pc.scores<-pca$scores[,1]
class<-ifelse(pc.scores >= 0, 1, 2)
BODY<-cbind(class,bodyfat)
summary(BODY)
BODY<-as.data.frame(BODY)
#=================================
#Linear discriminant analysis
#=================================
library(MASS)
Out1=matrix(0,nrow(BODY),1 )
for ( i in 1 :nrow(BODY)){
  linear<- lda(class~.,data=BODY[-i,])
  pred=predict(linear,BODY[i,])
  Out1[i,]<-pred$class
}
linear$prior
linear$scaling
tab1 <- table( Out1 , Actual = BODY$class)
tab1
missclassifiation<-round(1-sum(diag(tab1))/sum(tab1),3)
missclassifiation
#=================================
#Multiple regression
#discriminant analysis
#=================================
class<-as.factor(BODY[,1])
class<-unclass(class) 
lda.reg<-lm(class~.,data=BODY)    
STEP<-step(lda.reg, direction = "backward", trace=FALSE ) 
summary(STEP)
head(BODY)
#=================================
#Logistic regression
#discriminant analysis
#=================================
BODY$class<-as.factor(BODY[,1])
N=nrow(BODY)
rvec <- runif(N)
BODYTR <- BODY[rvec < 0.75,]
BODYTS <- BODY[rvec >= 0.75,]
BODYLOG<- glm(class~., data =BODYTR, family = binomial(link="logit"))
summary(BODYLOG)$coefficients
pred=predict(BODYLOG,BODYTS,type="response")
Z<-ifelse(pred<0.46,1,2)
tab2 <- table(Z , Actual = BODYTS$class)
tab2
missclassifiation<-round(1-sum(diag(tab2))/sum(tab2),3)
missclassifiation
#=================================
#Quadratic discriminant analysis
#=================================
Out1=matrix(0,nrow(BODY),1 )
for ( i in 1 :nrow(BODY)){
  quad <- qda(class~.,data=BODY[-i,])
  pred=predict(quad,BODY[i,])
  Out1[i,]<-pred$class
}
tab1 <- table( Out1 , Actual = BODY$class)
tab1
missclassifiation<-round(1-sum(diag(tab1))/sum(tab1),3)
missclassifiation
